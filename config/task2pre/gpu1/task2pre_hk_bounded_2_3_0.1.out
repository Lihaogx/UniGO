Seed set to 1234
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: logger/2024-05-21_01-13_1234_1234
Traceback (most recent call last):
  File "/home/lh/MOGO/main.py", line 203, in <module>
    main(args)
  File "/home/lh/MOGO/main.py", line 143, in main
    trainer.fit(model_module, datamodule=data_module, ckpt_path=initial_ckpt_path)
  File "/home/lh/miniconda3/envs/mogo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/home/lh/miniconda3/envs/mogo/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/lh/miniconda3/envs/mogo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/lh/miniconda3/envs/mogo/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 949, in _run
    call._call_setup_hook(self)  # allow user to set up LightningModule in accelerator environment
  File "/home/lh/miniconda3/envs/mogo/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 92, in _call_setup_hook
    _call_lightning_datamodule_hook(trainer, "setup", stage=fn)
  File "/home/lh/miniconda3/envs/mogo/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 179, in _call_lightning_datamodule_hook
    return fn(*args, **kwargs)
  File "/home/lh/MOGO/data/data_interface.py", line 24, in setup
    full_dataset = Graph_OD_dataset(self.file_path_train, self.data_config)
  File "/home/lh/MOGO/data/od_data.py", line 80, in __init__
    self.load_data()
  File "/home/lh/MOGO/data/od_data.py", line 83, in load_data
    if 'synthetic_data' in self.file_path:
TypeError: argument of type 'NoneType' is not iterable
